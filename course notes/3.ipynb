{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc\n",
    "sqlContext = SQLContext(sc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/simple-linear-regression-tutorial-for-machine-learning/ <br>\n",
    "https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python/ <br>\n",
    "algorithm details: *Latent dirichlet allocation*, MI Jordan\n",
    "\n",
    "**MLlib**\n",
    "* includes RDD-based and DataFrame-based API\n",
    "* As of Spark 2.0, the RDD-based APIs in the `spark.mllib` package have entered maintenance mode. The primary Machine Learning API for Spark is now the DataFrame-based API in the `spark.ml` package.\n",
    "\n",
    "# Spark ML (MLlib DataFrame-based API)\n",
    "\n",
    "* New (Spark v 1.2).\n",
    "* Support Pipelines of estimators, transformer and evaluators. \n",
    "* Use DataFrame and Dataset.\n",
    "    * Dataset : A strongly typed collection of objects (This includes DataFrame.).\n",
    "\n",
    "# MainComponents\n",
    "* Transformers<br>\n",
    "`transform()`: takes DataFrame and optional parameters.\n",
    "     * Convert a dataset to another. \n",
    "     * Types <br>\n",
    "        1) Feature transformer – take a data frame output a data frame with new columns like feature vectors. <br>\n",
    "        2) Learning model – take a data frame and output a data frame with predicted labels. <br>\n",
    "* Estimators<br>\n",
    "`fit()` : takes a DataFrame and parameters.\n",
    "     * Algorithms that produce transformers by\n",
    "     * Ex. Linear regression produces a linear regression model with fitted weights and an intercepts, which is a transformer.\n",
    "* Evaluators<br>\n",
    "`Evaluator()`\n",
    "     * Evaluate the performance of a model.   \n",
    "<br>\n",
    "  <br>\n",
    "* ML Parameters\n",
    "     * Specify parameters for estimators and transformers.\n",
    "     * Also can use `ParamGridBuilder()` for choosing the model produced by the best-performing set of parameters in `CrossValidator()`.\n",
    "* ML Pipeline (`PipelineModel()`)\n",
    "     * In machine learning, the same steps are often repeated with slightly different parameters to find the best results.\n",
    "     * A Pipeline chains multiple Transformers and Estimators together to specify an ML workflow and runs in order.\n",
    "\n",
    "# Algorithms\n",
    "\n",
    "## Logistic Regression \n",
    "`LogisticRegression()`\n",
    "* Input\n",
    "    1. features - Feature vector.\n",
    "    2. label - Label to predict.\n",
    "* Output<br>\n",
    "Coefficient and intercept of the model.\n",
    "\n",
    "\n",
    "## Decision Tree\n",
    "* Pros <br>\n",
    "Do not require data normalization, can handle numerical/categorical values, and work with missing values.\n",
    "* Cons <br>\n",
    "Prone to overfitting and is sensitive to the input data.\n",
    "  \n",
    "`DecisionTreeClassifier()` - Binary Decision Tree classifier.\n",
    "* Input\n",
    "    1. features - Feature vector.\n",
    "    2. label - Label to predict.\n",
    "* Output\n",
    "    1. prediction – Predicted label.\n",
    "    2. rawPrediction - Vector of length # classes, with the counts of training instance labels at the tree node which makes the prediction.\n",
    "    3. probability - Vector of length # classes equal to rawPrediction normalized to a multinomial distribution\n",
    "\n",
    "## Random Forest (EX4)\n",
    "* Ensemble learning method\n",
    "    * Train a certain number of decision trees on data randomly sampled from the original data. \n",
    "    * Avoid overfitting and find a global optima that particular decision tree cannot find on\n",
    "    their own.\n",
    "* Performs well on high dimensional datasets.\n",
    "  \n",
    "`RandomForestClassifier`\n",
    "* Parameters\n",
    "    * numTrees : The number of trees to train. Default : 20 \n",
    "    * featureSubsetStrategy\n",
    "        * all – use all features.\n",
    "        * onethird – randomly selects 1/3 of the features.\n",
    "        * sqrt – randomly select sqrt(number of features).\n",
    "        * log2 – randomly select log2(number of features).\n",
    "        * auto – sqrt for classification and onethird for regression (default)\n",
    "* Make sure to have enough driver memory (configuration)<br>\n",
    "`pyspark --driver-memory=2g`\n",
    "<br>\n",
    "  <br>\n",
    "* Input\n",
    "    1. features - Feature vector.\n",
    "    2. label - Label to predict.\n",
    "* Output\n",
    "    1. prediction – Predicted label.\n",
    "    2. rawPrediction - Vector of length # classes, with the counts of training instance labels at\n",
    "    the tree node which makes the prediction.\n",
    "    3. probability - Vector of length # classes equal to rawPrediction normalized to a multinomial distribution.\n",
    "\n",
    "## K-Mean Clustering (EX5)\n",
    "* Unsupervised learning\n",
    "* Dataset should be standardized.\n",
    "* Example – partition data into groups, anomaly detection, text/topic categorization\n",
    "<br>\n",
    "  <br>\n",
    "`Kmeans`\n",
    "* Parameters\n",
    "    * k : Number of clusters to find (default – 2).\n",
    "    * maxIter : Maximum number of iterations (default – 20). \n",
    "    * tol : Convergence tolerance (default – 0.0001).\n",
    "    * seed : Random seed value for cluster initialization.\n",
    "<br>\n",
    "  <br>\n",
    "* Input<br>\n",
    "features – feature vector \n",
    "* Output<br>\n",
    "prediction – predicted cluster center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex1\n",
    "Develop a Simple Linear Regression model(without stochastic gradient descent) to predict “petal_width” using “sepal_width” using “iris.csv”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext.sql(\"DROP TABLE IF EXISTS test\") #delete test table, if exsists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "irisSchema = StructType([StructField(\"sepal_length\", DoubleType(), True), \n",
    "                         StructField(\"sepal_width\", DoubleType(), True),\n",
    "                         StructField(\"petal_length\", DoubleType(), True), \n",
    "                         StructField(\"petal_width\", DoubleType(), True),\n",
    "                         StructField(\"class\", StringType(), True)])\n",
    "\n",
    "iris = sqlContext.read.format('com.databricks.spark.csv').options(header='false')\\\n",
    "    .load('2018-msan697-example/Data/iris.csv', schema = irisSchema)\\\n",
    "    .select(\"sepal_length\", \"petal_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = iris.randomSplit([0.9, 0.1])\n",
    "train.cache()\n",
    "test.write.saveAsTable(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.287408759124089"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance = train.cov(\"sepal_length\", \"petal_length\")\n",
    "covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7042840274796065"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = train.select(variance(\"sepal_length\")).first()[0]\n",
    "var  #Row(0.6608711484593822)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8279681334408335"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_0 = covariance / var\n",
    "coeff_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.873057760043645"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_1 = train.select(mean(\"petal_length\")).first()[0] - coeff_0 * train.select(mean(\"sepal_length\")).first()[0]\n",
    "coeff_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+------------------+\n",
      "|sepal_length|petal_length|        prediction|\n",
      "+------------+------------+------------------+\n",
      "|         5.0|         1.6|2.2667829071599996|\n",
      "|         5.2|         1.5|2.6323765338479994|\n",
      "|         5.2|         1.5|2.6323765338479994|\n",
      "|         5.4|         1.5| 2.997970160536001|\n",
      "|         5.4|         1.5| 2.997970160536001|\n",
      "|         5.4|         1.7| 2.997970160536001|\n",
      "|         5.8|         4.0|3.7291574139119987|\n",
      "|         6.1|         4.0| 4.277547853943998|\n",
      "|         6.2|         4.3|    4.460344667288|\n",
      "|         6.3|         4.7|    4.643141480632|\n",
      "|         6.4|         5.6|    4.825938293976|\n",
      "|         6.9|         5.4| 5.739922360696001|\n",
      "|         7.4|         6.1|6.6539064274160005|\n",
      "+------------+------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_output = sqlContext.sql(\"SELECT sepal_length, petal_length, sepal_length * {0} + {1} AS prediction FROM test\".format(coeff_0, coeff_1))\n",
    "test_output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936774199917817"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rmse (root mean squre error) : https://en.wikipedia.org/wiki/Root-mean-square_deviation\n",
    "rmse = math.sqrt(test_output.rdd.map(lambda x : (x[\"prediction\"] - x[\"petal_length\"])**2)\\\n",
    "                      .reduce(lambda x,y : x + y)/test_output.count())\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithms\n",
    "\n",
    "## Logistic Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex2\n",
    "Adult Data Set : Prediction task is to determine whether a person makes over 50K a year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toDoubleSafe(v):\n",
    "    try:\n",
    "        return float(v)\n",
    "    except ValueError:\n",
    "        return v #if it is not a float type, return a string\n",
    "\n",
    "census_raw = sc.textFile('2018-msan697-example/Data/adult.raw').map(lambda x:x.split(\", \"))\\\n",
    "    .map(lambda row: [toDoubleSafe(x) for x in row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[39.0,\n",
       "  u'State-gov',\n",
       "  77516.0,\n",
       "  u'Bachelors',\n",
       "  u'Never-married',\n",
       "  u'Adm-clerical',\n",
       "  u'Not-in-family',\n",
       "  u'White',\n",
       "  u'Male',\n",
       "  2174.0,\n",
       "  0.0,\n",
       "  40.0,\n",
       "  u'United-States',\n",
       "  u'<=50K']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "census_raw.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Convert the RDD to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adultschema = StructType([\n",
    "    StructField(\"age\",DoubleType(),True),\n",
    "    StructField(\"capital_gain\",DoubleType(),True),\n",
    "    StructField(\"capital_loss\",DoubleType(),True),\n",
    "    StructField(\"fnlwgt\",DoubleType(),True),\n",
    "    StructField(\"hours_per_week\",DoubleType(),True),\n",
    "    StructField(\"education\",StringType(),True),\n",
    "    StructField(\"income\",StringType(),True),\n",
    "    StructField(\"marital_status\",StringType(),True),\n",
    "    StructField(\"native_country\",StringType(),True),\n",
    "    StructField(\"occupation\",StringType(),True),\n",
    "    StructField(\"race\",StringType(),True),\n",
    "    StructField(\"relationship\",StringType(),True),\n",
    "    StructField(\"sex\",StringType(),True),\n",
    "    StructField(\"workclass\",StringType(),True),\n",
    "])\n",
    "\n",
    "columns = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"marital_status\",\n",
    "           \"occupation\", \"relationship\", \"race\", \"sex\", \"capital_gain\", \"capital_loss\",\n",
    "           \"hours_per_week\", \"native_country\", \"income\"]\n",
    "\n",
    "dfraw = sqlContext.createDataFrame(census_raw.map(lambda row: Row(**{x[0]:x[1] for x in zip(columns, row)}), adultschema))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.clean data <br>\n",
    "Missing data imputation - Impute the most common row for \"?\".\n",
    "* `.na` : returns a DataFrameNA Function for handling missing values. \n",
    "* `.replace(to_replace, value, subset=None)`\n",
    "     * `to_replace` : Value to be replaced.\n",
    "     * `value` : Value to use to replace holes.\n",
    "     * `subset` : Optional list of column names to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfrawrp = dfraw.na.replace([\"?\"], [\"Private\"], [\"workclass\"])\n",
    "dfrawrpl = dfrawrp.na.replace([\"?\"], [\"Prof-specialty\"], [\"occupation\"])\n",
    "dfrawnona = dfrawrpl.na.replace([\"?\"], [\"United-States\"], [\"native_country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Strings to Categorical Values\n",
    "  \n",
    "1.String Indexer:\n",
    "When male (0) and female (1), female > male? \n",
    "* Convert string categorical values into integer indexes.\n",
    "* Takes a DataFrame and fits a `StringIndexerModel()` and used it for transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting strings to numeric values\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "def indexStringColumns(df, cols):\n",
    "    #variable newdf will be updated several times\n",
    "    newdf = df\n",
    "    \n",
    "    for c in cols:\n",
    "        #For each given colum, fits StringIndexerModel.\n",
    "        si = StringIndexer(inputCol=c, outputCol=c+\"-num\")\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-num\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-num\" suffix. \n",
    "        newdf = si.fit(newdf).transform(newdf).drop(c).withColumnRenamed(c+\"-num\", c)\n",
    "    return newdf\n",
    "\n",
    "dfnumeric = indexStringColumns(dfrawnona, [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\", \"income\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+--------+--------------+---------+---------+--------------+----------+------------+----+---+--------------+------+\n",
      "| age|capital_gain|capital_loss|  fnlwgt|hours_per_week|workclass|education|marital_status|occupation|relationship|race|sex|native_country|income|\n",
      "+----+------------+------------+--------+--------------+---------+---------+--------------+----------+------------+----+---+--------------+------+\n",
      "|39.0|      2174.0|         0.0| 77516.0|          40.0|      3.0|      2.0|           1.0|       3.0|         1.0| 0.0|0.0|           0.0|   0.0|\n",
      "|50.0|         0.0|         0.0| 83311.0|          13.0|      1.0|      2.0|           0.0|       2.0|         0.0| 0.0|0.0|           0.0|   0.0|\n",
      "|38.0|         0.0|         0.0|215646.0|          40.0|      0.0|      0.0|           2.0|       8.0|         1.0| 0.0|0.0|           0.0|   0.0|\n",
      "|53.0|         0.0|         0.0|234721.0|          40.0|      0.0|      5.0|           0.0|       8.0|         0.0| 1.0|0.0|           0.0|   0.0|\n",
      "|28.0|         0.0|         0.0|338409.0|          40.0|      0.0|      2.0|           0.0|       0.0|         4.0| 1.0|1.0|           8.0|   0.0|\n",
      "+----+------------+------------+--------+--------------+---------+---------+--------------+----------+------------+----+---+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfnumeric.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.One-hot encoding:\n",
    "    * Expand a column to as many columns as there are distinct strings in it and only one column contains a 1 and others are 0.\n",
    "    * Create a new column as a one-hot-encoded sparse vector. (Replace a column with a vector.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "def oneHotEncodeColumns(df, cols):\n",
    "    newdf = df\n",
    "    for c in cols:\n",
    "        #For each given colum, create OneHotEncoder. \n",
    "        #dropLast : Whether to drop the last category in the encoded vector (default: true)\n",
    "        onehotenc = OneHotEncoder(inputCol=c, outputCol=c+\"-onehot\", dropLast=False)\n",
    "        #Creates a DataFame by putting the transformed values in the new colum with suffix \"-onehot\" \n",
    "        #and then drops the original columns.\n",
    "        #and drop the \"-onehot\" suffix. \n",
    "        newdf = onehotenc.transform(newdf).drop(c).withColumnRenamed(c+\"-onehot\", c)\n",
    "    return newdf\n",
    "\n",
    "dfhot = oneHotEncodeColumns(dfnumeric, [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"native_country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+------------+--------+--------------+---+------+-------------+--------------+--------------+--------------+-------------+-------------+--------------+\n",
      "| age|capital_gain|capital_loss|  fnlwgt|hours_per_week|sex|income|    workclass|     education|marital_status|    occupation| relationship|         race|native_country|\n",
      "+----+------------+------------+--------+--------------+---+------+-------------+--------------+--------------+--------------+-------------+-------------+--------------+\n",
      "|39.0|      2174.0|         0.0| 77516.0|          40.0|0.0|   0.0|(8,[3],[1.0])|(16,[2],[1.0])| (7,[1],[1.0])|(14,[3],[1.0])|(6,[1],[1.0])|(5,[0],[1.0])|(41,[0],[1.0])|\n",
      "|50.0|         0.0|         0.0| 83311.0|          13.0|0.0|   0.0|(8,[1],[1.0])|(16,[2],[1.0])| (7,[0],[1.0])|(14,[2],[1.0])|(6,[0],[1.0])|(5,[0],[1.0])|(41,[0],[1.0])|\n",
      "|38.0|         0.0|         0.0|215646.0|          40.0|0.0|   0.0|(8,[0],[1.0])|(16,[0],[1.0])| (7,[2],[1.0])|(14,[8],[1.0])|(6,[1],[1.0])|(5,[0],[1.0])|(41,[0],[1.0])|\n",
      "|53.0|         0.0|         0.0|234721.0|          40.0|0.0|   0.0|(8,[0],[1.0])|(16,[5],[1.0])| (7,[0],[1.0])|(14,[8],[1.0])|(6,[0],[1.0])|(5,[1],[1.0])|(41,[0],[1.0])|\n",
      "|28.0|         0.0|         0.0|338409.0|          40.0|1.0|   0.0|(8,[0],[1.0])|(16,[2],[1.0])| (7,[0],[1.0])|(14,[0],[1.0])|(6,[4],[1.0])|(5,[1],[1.0])|(41,[8],[1.0])|\n",
      "+----+------------+------------+--------+--------------+---+------+-------------+--------------+--------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|    workclass|\n",
      "+-------------+\n",
      "|(8,[3],[1.0])|\n",
      "|(8,[1],[1.0])|\n",
      "|(8,[0],[1.0])|\n",
      "|(8,[0],[1.0])|\n",
      "|(8,[0],[1.0])|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfhot.select('workclass').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.`VectorAssembler()`\n",
    "    * Merge all the new vectors and the original columns into a single vector.\n",
    "    * Useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like logistic regression and decision trees.\n",
    "    * ML algorithms work with two columns called **features** and **label** by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging the data with Vector Assembler.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "input_cols=[\"age\",\"capital_gain\",\"capital_loss\",\"fnlwgt\",\"hours_per_week\",\"sex\",\"workclass\",\"education\",\"marital_status\",\"occupation\",\"relationship\",\"native_country\",\"race\"]\n",
    "\n",
    "#VectorAssembler takes a number of collumn names(inputCols) and output column name (outputCol)\n",
    "#and transforms a DataFrame to assemble the values in inputCols into one single vector with outputCol.\n",
    "va = VectorAssembler(outputCol=\"features\", inputCols=input_cols)\n",
    "#lpoints - labeled data.\n",
    "lpoints = va.transform(dfhot).select(\"features\", \"income\").withColumnRenamed(\"income\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(103,[0,1,3,4,9,1...|  0.0|\n",
      "|(103,[0,3,4,7,16,...|  0.0|\n",
      "|(103,[0,3,4,6,14,...|  0.0|\n",
      "|(103,[0,3,4,6,19,...|  0.0|\n",
      "|(103,[0,3,4,5,6,1...|  0.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lpoints.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(features=SparseVector(103, {0: 39.0, 1: 2174.0, 3: 77516.0, 4: 40.0, 9: 1.0, 16: 1.0, 31: 1.0, 40: 1.0, 52: 1.0, 57: 1.0, 98: 1.0}))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lpoints.select(\"features\").first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = lpoints.randomSplit([0.8, 0.2])\n",
    "\n",
    "#cache() : the algorithm is interative and training and data sets are going to be reused many times.\n",
    "adulttrain = splits[0].cache()\n",
    "adultvalid = splits[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.train the model<br>\n",
    "Use Spark ML’s LogisticRegression\n",
    "* Set parameters - regParam, maxIter, fitIntercept. \n",
    "* Call `fit()` passing in a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Train the model.\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(regParam=0.01, maxIter=1000, fitIntercept=True)\n",
    "lrmodel = lr.fit(adulttrain)\n",
    "#The above lines are same as..\n",
    "#lr = LogisticRegression()\n",
    "#lrmodel = lr.setParams(regParam=0.01, maxIter=1000, fitIntercept=True).fit(adulttrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Interpret the model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0203666857287,0.000140220907508,0.000554517771619,6.94529720864e-07,0.0278534727572,-0.507946988682,0.0198222944162,-0.360971401411,0.053705938659,-0.144947228877,0.264275465667,0.583707064995,-0.613487125557,-1.27081028531,-0.364152225981,-0.0098648845072,0.753315446034,1.11428853791,0.184552881965,-0.946854758573,0.217275533796,-1.11377811006,-1.36017731604,1.65935804497,-1.31927475606,-0.641114076647,1.66411894239,-1.16617532793,-1.48301831848,-1.76967194024,0.852228560536,-0.703211078991,-0.280467622288,-0.358005824639,-0.366563354955,-0.142635801563,0.852837814675,0.205469503478,0.0324821853417,0.649081542716,-0.0362816362082,0.20645767832,-0.723211930094,-0.29060233814,-0.115317262782,-0.604288538632,-0.89554312879,0.47082797088,0.316786449609,-0.874597667244,0.487395927952,0.439071849565,-0.0913080035768,-0.769163801196,-0.329072808892,1.29410003445,-0.511363843502,0.18826521387,-0.617537876063,0.347334208822,0.151961744465,-0.26541465854,0.424595235834,-0.26712102011,0.0971839787834,-0.00440158318064,0.398436771529,-0.273248471781,-0.872297401724,0.127321480862,0.636978744126,-0.868505648205,0.107820694194,-0.0983178896374,-0.0455400569953,-0.749316161512,-1.24911324695,0.17648888746,0.449449393004,0.104598858231,0.168546831232,-0.100829810549,-0.581770388963,-0.502213550017,0.186056949407,0.722314368117,0.988668188628,-0.237269801664,-0.225666364954,0.710786459017,-0.732006250894,0.1540344877,-1.68040123702,-0.58062561151,-0.671394537451,0.00532612680392,0.373084288748,0.0,0.0733417480849,-0.120153717886,0.115244473444,-0.243836985746,0.0237224675688]\n",
      "-4.36678861599\n"
     ]
    }
   ],
   "source": [
    "print(lrmodel.coefficients)\n",
    "print(lrmodel.intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.Evaluate classification models.\n",
    "* First use lrmodel (the developedlinear regression model) to transform the test dataset. \n",
    "* Then use `BinaryClassificationEvaluator()` to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[-0.8952527154192...|[0.29002704192954...|       1.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[0.58240439636611...|[0.64162047005141...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[0.24099982801490...|[0.55996002643418...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[-0.4505158580492...|[0.38923812317998...|       1.0|\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[-0.0728871902597...|[0.48178626515791...|       1.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[1.02311688947125...|[0.73557928693190...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[0.45643230683104...|[0.61216747966224...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[-0.9878836978227...|[0.27133028955709...|       1.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[0.62570003326136...|[0.65151381956458...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[4.76765896563305...|[0.99157138907531...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[3.66867718697986...|[0.97512438878690...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[4.66973917059212...|[0.99071235461368...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[3.94185522304228...|[0.98095748899418...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[4.75892164155806...|[0.99149805176405...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[1.03651607383107...|[0.73817722101169...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[2.0688888242078,...|[0.88784236011875...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[-0.0028026827280...|[0.49929932977664...|       1.0|\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[0.19809619373631...|[0.54936272914209...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  0.0|[0.38083988393272...|[0.59407565674442...|       0.0|\n",
      "|(103,[0,1,3,4,5,6...|  1.0|[0.11410144055360...|[0.52849445240855...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluate models using test dataset.\n",
    "#First, transform the validation set.\n",
    "validpredicts = lrmodel.transform(adultvalid)\n",
    "validpredicts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rawPrediction : log-odds that a sample doesn’t/does belong to the category. <br>\n",
    "probability : the probability that the sample is not in the category. <br>\n",
    "prediction : proability that the sample belongs to the category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(rawPrediction=DenseVector([-0.8953, 0.8953]))\n",
      "Row(probability=DenseVector([0.29, 0.71]))\n"
     ]
    }
   ],
   "source": [
    "print validpredicts.select(\"rawPrediction\").first()\n",
    "print validpredicts.select(\"probability\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "areaUnderROC:0.900088781294\n",
      "areaUnderPR:0.748368696343\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model. default metric : Area Under ROC(rate of correct)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "bceval = BinaryClassificationEvaluator()\n",
    "print (bceval.getMetricName() +\":\" + str(bceval.evaluate(validpredicts)))\n",
    "\n",
    "#Evaluate the model. metric : Area Under PR(precision recall)\n",
    "bceval.setMetricName(\"areaUnderPR\")\n",
    "print (bceval.getMetricName() +\":\" + str(bceval.evaluate(validpredicts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n-fold cross-validation: \n",
    "* Validate the performance of the model more reliably.\n",
    "* Divide the dataset into n subsets of equal sizes and train n models excluding a different subset each time and train all n models.\n",
    "* Calculate the mean error for all n models.\n",
    "* Choose the set of parameters with the smallest average error.\n",
    "  \n",
    "`CrossValidator` class : estimator.\n",
    "* Takes estimator, evaluator and number of folds to use. \n",
    "* Takes several parameters in `setEstimatorParamMaps()`<br>\n",
    "`ParamGridBuilder()` – combinations of parameters and their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# n-fold validation and the results.\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "#ParamGridBuilder() – combinations of parameters and their values.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "            .addGrid(lr.maxIter, [100, 1000])\\\n",
    "            .addGrid(lr.regParam, [0.0001, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5])\\\n",
    "            .build()\n",
    "            \n",
    "#setEstimatorParamMaps() takes ParamGridBuilder().\n",
    "cv = CrossValidator().setEstimator(lr).setEvaluator(bceval).setNumFolds(5).setEstimatorParamMaps(paramGrid)\n",
    "cvmodel = cv.fit(adulttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0228384155137,0.000308060135547,0.000650968290685,8.23615498754e-07,0.0314787008101,-0.696023913327,-0.438392164269,-0.896704263015,-0.42265891452,-0.643995661333,-0.245424314708,0.164968174463,-1.1579958258,-4.63564017146,-0.619089853,-0.219869083772,0.604249500722,0.992013944789,-0.0354232108078,-1.43228769298,0.0300974811123,-1.56142495592,-1.86313222762,1.63008484725,-1.8462056879,-1.00586573922,1.62504110907,-1.62437727519,-2.23146802747,-5.96026277956,1.33998491831,-1.51690279064,-1.03844090324,-1.12079846896,-1.14773616395,-0.867815600293,1.40486027677,-0.0281622218137,-0.158294630169,0.470408387375,-0.232423108134,0.0022364954838,-1.0777475676,-0.497423376013,-0.317349449207,-0.87755147686,-1.26256871455,0.303293442641,0.15372041142,-1.64944942298,0.368932088742,-0.472524045373,0.19112789408,-0.966526616356,-0.0234915370912,0.662285012638,-0.899442819457,-1.03768029307,-1.93334108735,-0.880638122059,-1.11435776535,-1.51953997346,-0.746047308625,-1.52848257843,-1.27909421785,-1.20544470144,-0.842410416126,-1.64594858353,-2.35400678784,-0.979759287706,-0.469035535315,-2.18120251096,-1.26424438257,-1.18880899781,-1.2324001965,-2.22772050163,-2.87124599026,-0.905499462543,-0.538805782856,-1.18084328175,-1.07472033751,-1.49767056563,-1.84582924011,-1.75733302584,-0.990619671432,-0.398309184573,-0.0906269245638,-1.51324557016,-1.52749256789,-0.550399609348,-2.09329842213,-1.28876440172,-3.44446961804,-1.77865528725,-2.03896584401,-1.09973194269,-0.797788656742,0.0,-0.7114259488,-0.923031389711,-0.592528368777,-1.10606296116,-0.696836335241]\n",
      "-1.39591785989\n",
      "1000\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "#You can access the selected model through `bestModel`.\n",
    "print cvmodel.bestModel.coefficients\n",
    "print cvmodel.bestModel.intercept\n",
    "print cvmodel.bestModel._java_obj.getMaxIter()\n",
    "print cvmodel.bestModel._java_obj.getRegParam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.902927650786\n",
      "0.761579460014\n"
     ]
    }
   ],
   "source": [
    "print BinaryClassificationEvaluator().evaluate(cvmodel.bestModel.transform(adultvalid))\n",
    "print BinaryClassificationEvaluator(metricName=\"areaUnderPR\").evaluate(cvmodel.bestModel.transform(adultvalid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "* Pros <br>\n",
    "Do not require data normalization, can handle numerical/categorical values, and work with missing values.\n",
    "* Cons <br>\n",
    "Prone to overfitting and is sensitive to the input data.\n",
    "  \n",
    "`DecisionTreeClassifier()` - Binary Decision Tree classifier.\n",
    "* Input\n",
    "    1. features - Feature vector.\n",
    "    2. label - Label to predict.\n",
    "* Output\n",
    "    1. prediction – Predicted label.\n",
    "    2. rawPrediction - Vector of length # classes, with the counts of training instance labels at the tree node which makes the prediction.\n",
    "    3. probability - Vector of length # classes equal to rawPrediction normalized to a multinomial distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ex3\n",
    "Optical Recognition of Handwritten Digits Data Sets. : Classify handwritten digits<br>\n",
    "1.Create an RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47.0,\n",
       " 100.0,\n",
       " 27.0,\n",
       " 81.0,\n",
       " 57.0,\n",
       " 37.0,\n",
       " 26.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 23.0,\n",
       " 56.0,\n",
       " 53.0,\n",
       " 100.0,\n",
       " 90.0,\n",
       " 40.0,\n",
       " 98.0,\n",
       " 8.0]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data and create an RDD (16 pixels and label)\n",
    "pen_raw = sc.textFile(\"2018-msan697-example/Data/penbased.dat\", 4)\\\n",
    "    .map(lambda x:  x.split(\", \")).map(lambda row: [float(x) for x in row])\n",
    "pen_raw.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Convert the RDD to DataFrame and Create a feature vector.\n",
    "* hard-coding way<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "penschema = StructType([\n",
    "    StructField(\"pix1\",DoubleType(),True),\n",
    "    StructField(\"pix2\",DoubleType(),True),\n",
    "    StructField(\"pix3\",DoubleType(),True),\n",
    "    StructField(\"pix4\",DoubleType(),True),\n",
    "    StructField(\"pix5\",DoubleType(),True),\n",
    "    StructField(\"pix6\",DoubleType(),True),\n",
    "    StructField(\"pix7\",DoubleType(),True),\n",
    "    StructField(\"pix8\",DoubleType(),True),\n",
    "    StructField(\"pix9\",DoubleType(),True),\n",
    "    StructField(\"pix10\",DoubleType(),True),\n",
    "    StructField(\"pix11\",DoubleType(),True),\n",
    "    StructField(\"pix12\",DoubleType(),True),\n",
    "    StructField(\"pix13\",DoubleType(),True),\n",
    "    StructField(\"pix14\",DoubleType(),True),\n",
    "    StructField(\"pix15\",DoubleType(),True),\n",
    "    StructField(\"pix16\",DoubleType(),True),\n",
    "    StructField(\"label\",DoubleType(),True)\n",
    "])\n",
    "\n",
    "dfpen = sqlContext.createDataFrame(pen_raw.map(lambda x : Row(x[0],x[1],x[2],x[3],x[4],x[5],x[6],x[7],x[8],x[9],x[10],x[11],x[12],x[13],x[14],x[15],x[16])), penschema)\n",
    "\n",
    "# Merging the data with Vector Assembler.\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "va = VectorAssembler(outputCol=\"features\", inputCols=dfpen.columns[0:-1]) #except the last col\n",
    "dfpen = va.transform(dfpen).select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[47.0,100.0,27.0,...|  8.0|\n",
      "|[0.0,89.0,27.0,10...|  2.0|\n",
      "|[0.0,57.0,31.0,68...|  1.0|\n",
      "|[0.0,100.0,7.0,92...|  4.0|\n",
      "|[0.0,67.0,49.0,83...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpen.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* easy way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a DataFrame\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "penschema = StructType([\n",
    "   StructField(\"features\", ArrayType(elementType=FloatType(),containsNull=False),True),\n",
    "   StructField(\"label\", DoubleType(),True)\n",
    "])\n",
    "dfpen = sqlContext.createDataFrame(pen_raw.map(lambda x : Row(x[0:-1],x[-1])), penschema)\n",
    "\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "dfpen = dfpen.select(list_to_vector_udf(dfpen[\"features\"]).alias(\"features\"),'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[47.0,100.0,27.0,...|  8.0|\n",
      "|[0.0,89.0,27.0,10...|  2.0|\n",
      "|[0.0,57.0,31.0,68...|  1.0|\n",
      "|[0.0,100.0,7.0,92...|  4.0|\n",
      "|[0.0,67.0,49.0,83...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfpen.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pendtsets = dfpen.randomSplit([0.8, 0.2])\n",
    "pendttrain = pendtsets[0].cache()\n",
    "pendtvalid = pendtsets[1].cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Train the data.<br>\n",
    "Parameters for `DecisionTreeClassifier`\n",
    "* `maxDepth` : maximum tree depth (default : 5).\n",
    "* `maxBins` : maximum number of bins when binning continuous features (default : 32).\n",
    "* `minInstancesPerNode` : minimum number of dataset samples each branch needs to have after a split (default : 1).\n",
    "* `minInfoGain` : minimum information gain for a split (default : 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the data.\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(maxDepth=20, maxBins= 32, minInstancesPerNode=1, minInfoGain = 0)\n",
    "dtmodel = dt.fit(pendttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4c8088e648581152a875) of depth 20 with 595 nodes\n",
      "  If (feature 15 <= 51.0)\n",
      "   If (feature 4 <= 41.0)\n",
      "    If (feature 9 <= 17.0)\n",
      "     If (feature 14 <= 71.0)\n",
      "      If (feature 5 <= 31.0)\n",
      "       If (feature 0 <= 29.0)\n",
      "        Predict: 4.0\n",
      "       Else (feature 0 > 29.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 5 > 31.0)\n",
      "       Predict: 6.0\n",
      "     Else (feature 14 > 71.0)\n",
      "      If (feature 10 <= 12.0)\n",
      "       If (feature 0 <= 35.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 0 > 35.0)\n",
      "        Predict: 8.0\n",
      "      Else (feature 10 > 12.0)\n",
      "       If (feature 11 <= 15.0)\n",
      "        Predict: 2.0\n",
      "       Else (feature 11 > 15.0)\n",
      "        If (feature 0 <= 0.0)\n",
      "         Predict: 7.0\n",
      "        Else (feature 0 > 0.0)\n",
      "         Predict: 4.0\n",
      "    Else (feature 9 > 17.0)\n",
      "     If (feature 1 <= 99.0)\n",
      "      If (feature 9 <= 62.0)\n",
      "       If (feature 7 <= 18.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 7 > 18.0)\n",
      "        If (feature 14 <= 21.0)\n",
      "         If (feature 6 <= 53.0)\n",
      "          If (feature 9 <= 27.0)\n",
      "           Predict: 6.0\n",
      "          Else (feature 9 > 27.0)\n",
      "           If (feature 1 <= 72.0)\n",
      "            Predict: 9.0\n",
      "           Else (feature 1 > 72.0)\n",
      "            If (feature 10 <= 17.0)\n",
      "             Predict: 1.0\n",
      "            Else (feature 10 > 17.0)\n",
      "             If (feature 5 <= 70.0)\n",
      "              Predict: 3.0\n",
      "             Else (feature 5 > 70.0)\n",
      "              Predict: 5.0\n",
      "         Else (feature 6 > 53.0)\n",
      "          If (feature 9 <= 47.0)\n",
      "           If (feature 0 <= 85.0)\n",
      "            Predict: 9.0\n",
      "           Else (feature 0 > 85.0)\n",
      "            Predict: 5.0\n",
      "          Else (feature 9 > 47.0)\n",
      "           Predict: 9.0\n",
      "        Else (feature 14 > 21.0)\n",
      "         If (feature 13 <= 22.0)\n",
      "          If (feature 12 <= 48.0)\n",
      "           If (feature 2 <= 53.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 2 > 53.0)\n",
      "            Predict: 8.0\n",
      "          Else (feature 12 > 48.0)\n",
      "           If (feature 0 <= 49.0)\n",
      "            If (feature 1 <= 72.0)\n",
      "             If (feature 2 <= 2.0)\n",
      "              Predict: 2.0\n",
      "             Else (feature 2 > 2.0)\n",
      "              Predict: 1.0\n",
      "            Else (feature 1 > 72.0)\n",
      "             Predict: 2.0\n",
      "           Else (feature 0 > 49.0)\n",
      "            Predict: 6.0\n",
      "         Else (feature 13 > 22.0)\n",
      "          If (feature 5 <= 76.0)\n",
      "           Predict: 4.0\n",
      "          Else (feature 5 > 76.0)\n",
      "           If (feature 0 <= 49.0)\n",
      "            If (feature 0 <= 22.0)\n",
      "             Predict: 7.0\n",
      "            Else (feature 0 > 22.0)\n",
      "             Predict: 4.0\n",
      "           Else (feature 0 > 49.0)\n",
      "            Predict: 9.0\n",
      "      Else (feature 9 > 62.0)\n",
      "       If (feature 0 <= 35.0)\n",
      "        If (feature 5 <= 91.0)\n",
      "         If (feature 5 <= 0.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 5 > 0.0)\n",
      "          If (feature 1 <= 90.0)\n",
      "           If (feature 0 <= 16.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 0 > 16.0)\n",
      "            Predict: 5.0\n",
      "          Else (feature 1 > 90.0)\n",
      "           Predict: 4.0\n",
      "        Else (feature 5 > 91.0)\n",
      "         If (feature 2 <= 9.0)\n",
      "          If (feature 1 <= 47.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 1 > 47.0)\n",
      "           Predict: 7.0\n",
      "         Else (feature 2 > 9.0)\n",
      "          If (feature 0 <= 10.0)\n",
      "           Predict: 5.0\n",
      "          Else (feature 0 > 10.0)\n",
      "           Predict: 9.0\n",
      "       Else (feature 0 > 35.0)\n",
      "        If (feature 13 <= 42.0)\n",
      "         If (feature 8 <= 52.0)\n",
      "          Predict: 5.0\n",
      "         Else (feature 8 > 52.0)\n",
      "          If (feature 3 <= 40.0)\n",
      "           Predict: 0.0\n",
      "          Else (feature 3 > 40.0)\n",
      "           If (feature 1 <= 94.0)\n",
      "            If (feature 12 <= 31.0)\n",
      "             If (feature 4 <= 30.0)\n",
      "              Predict: 9.0\n",
      "             Else (feature 4 > 30.0)\n",
      "              Predict: 5.0\n",
      "            Else (feature 12 > 31.0)\n",
      "             Predict: 9.0\n",
      "           Else (feature 1 > 94.0)\n",
      "            If (feature 7 <= 61.0)\n",
      "             Predict: 4.0\n",
      "            Else (feature 7 > 61.0)\n",
      "             If (feature 5 <= 74.0)\n",
      "              Predict: 9.0\n",
      "             Else (feature 5 > 74.0)\n",
      "              Predict: 5.0\n",
      "        Else (feature 13 > 42.0)\n",
      "         If (feature 5 <= 13.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 5 > 13.0)\n",
      "          Predict: 4.0\n",
      "     Else (feature 1 > 99.0)\n",
      "      If (feature 13 <= 16.0)\n",
      "       If (feature 7 <= 71.0)\n",
      "        If (feature 10 <= 59.0)\n",
      "         If (feature 11 <= 13.0)\n",
      "          Predict: 6.0\n",
      "         Else (feature 11 > 13.0)\n",
      "          If (feature 0 <= 49.0)\n",
      "           Predict: 4.0\n",
      "          Else (feature 0 > 49.0)\n",
      "           Predict: 1.0\n",
      "        Else (feature 10 > 59.0)\n",
      "         If (feature 2 <= 25.0)\n",
      "          If (feature 14 <= 79.0)\n",
      "           If (feature 0 <= 0.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 0 > 0.0)\n",
      "            Predict: 9.0\n",
      "          Else (feature 14 > 79.0)\n",
      "           Predict: 4.0\n",
      "         Else (feature 2 > 25.0)\n",
      "          Predict: 5.0\n",
      "       Else (feature 7 > 71.0)\n",
      "        If (feature 8 <= 52.0)\n",
      "         Predict: 1.0\n",
      "        Else (feature 8 > 52.0)\n",
      "         Predict: 9.0\n",
      "      Else (feature 13 > 16.0)\n",
      "       If (feature 15 <= 0.0)\n",
      "        If (feature 7 <= 67.0)\n",
      "         If (feature 3 <= 50.0)\n",
      "          If (feature 0 <= 49.0)\n",
      "           Predict: 4.0\n",
      "          Else (feature 0 > 49.0)\n",
      "           Predict: 0.0\n",
      "         Else (feature 3 > 50.0)\n",
      "          If (feature 9 <= 20.0)\n",
      "           If (feature 6 <= 7.0)\n",
      "            Predict: 4.0\n",
      "           Else (feature 6 > 7.0)\n",
      "            Predict: 6.0\n",
      "          Else (feature 9 > 20.0)\n",
      "           If (feature 9 <= 84.0)\n",
      "            Predict: 4.0\n",
      "           Else (feature 9 > 84.0)\n",
      "            If (feature 6 <= 61.0)\n",
      "             Predict: 9.0\n",
      "            Else (feature 6 > 61.0)\n",
      "             Predict: 4.0\n",
      "        Else (feature 7 > 67.0)\n",
      "         If (feature 0 <= 59.0)\n",
      "          Predict: 4.0\n",
      "         Else (feature 0 > 59.0)\n",
      "          If (feature 2 <= 56.0)\n",
      "           Predict: 9.0\n",
      "          Else (feature 2 > 56.0)\n",
      "           Predict: 5.0\n",
      "       Else (feature 15 > 0.0)\n",
      "        If (feature 0 <= 85.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 0 > 85.0)\n",
      "         Predict: 6.0\n",
      "   Else (feature 4 > 41.0)\n",
      "    If (feature 15 <= 27.0)\n",
      "     If (feature 10 <= 36.0)\n",
      "      If (feature 12 <= 37.0)\n",
      "       If (feature 6 <= 71.0)\n",
      "        If (feature 15 <= 11.0)\n",
      "         If (feature 9 <= 66.0)\n",
      "          If (feature 2 <= 30.0)\n",
      "           If (feature 3 <= 90.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 3 > 90.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 2 > 30.0)\n",
      "           If (feature 4 <= 99.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 4 > 99.0)\n",
      "            If (feature 5 <= 91.0)\n",
      "             Predict: 2.0\n",
      "            Else (feature 5 > 91.0)\n",
      "             Predict: 1.0\n",
      "         Else (feature 9 > 66.0)\n",
      "          Predict: 5.0\n",
      "        Else (feature 15 > 11.0)\n",
      "         If (feature 0 <= 19.0)\n",
      "          Predict: 7.0\n",
      "         Else (feature 0 > 19.0)\n",
      "          Predict: 6.0\n",
      "       Else (feature 6 > 71.0)\n",
      "        If (feature 13 <= 12.0)\n",
      "         If (feature 9 <= 20.0)\n",
      "          If (feature 8 <= 48.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 8 > 48.0)\n",
      "           Predict: 1.0\n",
      "         Else (feature 9 > 20.0)\n",
      "          If (feature 3 <= 74.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 3 > 74.0)\n",
      "           If (feature 15 <= 11.0)\n",
      "            If (feature 2 <= 98.0)\n",
      "             If (feature 10 <= 23.0)\n",
      "              Predict: 2.0\n",
      "             Else (feature 10 > 23.0)\n",
      "              If (feature 2 <= 61.0)\n",
      "               Predict: 2.0\n",
      "              Else (feature 2 > 61.0)\n",
      "               Predict: 1.0\n",
      "            Else (feature 2 > 98.0)\n",
      "             Predict: 1.0\n",
      "           Else (feature 15 > 11.0)\n",
      "            Predict: 7.0\n",
      "        Else (feature 13 > 12.0)\n",
      "         If (feature 3 <= 93.0)\n",
      "          If (feature 5 <= 68.0)\n",
      "           Predict: 0.0\n",
      "          Else (feature 5 > 68.0)\n",
      "           Predict: 1.0\n",
      "         Else (feature 3 > 93.0)\n",
      "          If (feature 0 <= 35.0)\n",
      "           Predict: 7.0\n",
      "          Else (feature 0 > 35.0)\n",
      "           If (feature 1 <= 86.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 86.0)\n",
      "            Predict: 1.0\n",
      "      Else (feature 12 > 37.0)\n",
      "       If (feature 3 <= 96.0)\n",
      "        If (feature 9 <= 27.0)\n",
      "         If (feature 1 <= 85.0)\n",
      "          If (feature 6 <= 66.0)\n",
      "           If (feature 12 <= 61.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 12 > 61.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 66.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 1 > 85.0)\n",
      "          If (feature 0 <= 54.0)\n",
      "           If (feature 0 <= 25.0)\n",
      "            Predict: 7.0\n",
      "           Else (feature 0 > 25.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 54.0)\n",
      "           Predict: 6.0\n",
      "        Else (feature 9 > 27.0)\n",
      "         If (feature 3 <= 85.0)\n",
      "          If (feature 7 <= 67.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 7 > 67.0)\n",
      "           If (feature 0 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 0.0)\n",
      "            If (feature 0 <= 59.0)\n",
      "             Predict: 8.0\n",
      "            Else (feature 0 > 59.0)\n",
      "             Predict: 9.0\n",
      "         Else (feature 3 > 85.0)\n",
      "          Predict: 2.0\n",
      "       Else (feature 3 > 96.0)\n",
      "        If (feature 14 <= 32.0)\n",
      "         If (feature 0 <= 29.0)\n",
      "          If (feature 0 <= 0.0)\n",
      "           Predict: 3.0\n",
      "          Else (feature 0 > 0.0)\n",
      "           Predict: 5.0\n",
      "         Else (feature 0 > 29.0)\n",
      "          Predict: 6.0\n",
      "        Else (feature 14 > 32.0)\n",
      "         If (feature 8 <= 19.0)\n",
      "          If (feature 11 <= 36.0)\n",
      "           If (feature 4 <= 49.0)\n",
      "            If (feature 12 <= 50.0)\n",
      "             If (feature 0 <= 10.0)\n",
      "              Predict: 2.0\n",
      "             Else (feature 0 > 10.0)\n",
      "              Predict: 1.0\n",
      "            Else (feature 12 > 50.0)\n",
      "             If (feature 1 <= 57.0)\n",
      "              If (feature 0 <= 16.0)\n",
      "               Predict: 2.0\n",
      "              Else (feature 0 > 16.0)\n",
      "               Predict: 1.0\n",
      "             Else (feature 1 > 57.0)\n",
      "              Predict: 2.0\n",
      "           Else (feature 4 > 49.0)\n",
      "            If (feature 12 <= 50.0)\n",
      "             If (feature 7 <= 26.0)\n",
      "              If (feature 4 <= 62.0)\n",
      "               Predict: 1.0\n",
      "              Else (feature 4 > 62.0)\n",
      "               Predict: 2.0\n",
      "             Else (feature 7 > 26.0)\n",
      "              If (feature 1 <= 66.0)\n",
      "               If (feature 0 <= 19.0)\n",
      "                Predict: 2.0\n",
      "               Else (feature 0 > 19.0)\n",
      "                Predict: 1.0\n",
      "              Else (feature 1 > 66.0)\n",
      "               Predict: 2.0\n",
      "            Else (feature 12 > 50.0)\n",
      "             Predict: 2.0\n",
      "          Else (feature 11 > 36.0)\n",
      "           Predict: 7.0\n",
      "         Else (feature 8 > 19.0)\n",
      "          If (feature 9 <= 7.0)\n",
      "           If (feature 6 <= 61.0)\n",
      "            If (feature 0 <= 10.0)\n",
      "             If (feature 1 <= 80.0)\n",
      "              Predict: 2.0\n",
      "             Else (feature 1 > 80.0)\n",
      "              Predict: 7.0\n",
      "            Else (feature 0 > 10.0)\n",
      "             If (feature 9 <= 6.0)\n",
      "              If (feature 4 <= 71.0)\n",
      "               Predict: 1.0\n",
      "              Else (feature 4 > 71.0)\n",
      "               If (feature 2 <= 51.0)\n",
      "                Predict: 2.0\n",
      "               Else (feature 2 > 51.0)\n",
      "                Predict: 1.0\n",
      "             Else (feature 9 > 6.0)\n",
      "              Predict: 2.0\n",
      "           Else (feature 6 > 61.0)\n",
      "            If (feature 12 <= 43.0)\n",
      "             Predict: 7.0\n",
      "            Else (feature 12 > 43.0)\n",
      "             If (feature 8 <= 41.0)\n",
      "              Predict: 2.0\n",
      "             Else (feature 8 > 41.0)\n",
      "              Predict: 1.0\n",
      "          Else (feature 9 > 7.0)\n",
      "           If (feature 4 <= 45.0)\n",
      "            If (feature 0 <= 0.0)\n",
      "             Predict: 2.0\n",
      "            Else (feature 0 > 0.0)\n",
      "             Predict: 1.0\n",
      "           Else (feature 4 > 45.0)\n",
      "            If (feature 9 <= 17.0)\n",
      "             If (feature 5 <= 88.0)\n",
      "              If (feature 4 <= 71.0)\n",
      "               If (feature 2 <= 53.0)\n",
      "                Predict: 2.0\n",
      "               Else (feature 2 > 53.0)\n",
      "                Predict: 1.0\n",
      "              Else (feature 4 > 71.0)\n",
      "               Predict: 2.0\n",
      "             Else (feature 5 > 88.0)\n",
      "              If (feature 6 <= 66.0)\n",
      "               Predict: 1.0\n",
      "              Else (feature 6 > 66.0)\n",
      "               If (feature 2 <= 58.0)\n",
      "                Predict: 2.0\n",
      "               Else (feature 2 > 58.0)\n",
      "                Predict: 1.0\n",
      "            Else (feature 9 > 17.0)\n",
      "             If (feature 4 <= 49.0)\n",
      "              If (feature 0 <= 0.0)\n",
      "               Predict: 2.0\n",
      "              Else (feature 0 > 0.0)\n",
      "               Predict: 1.0\n",
      "             Else (feature 4 > 49.0)\n",
      "              If (feature 3 <= 99.0)\n",
      "               If (feature 15 <= 6.0)\n",
      "                Predict: 2.0\n",
      "               Else (feature 15 > 6.0)\n",
      "                Predict: 1.0\n",
      "              Else (feature 3 > 99.0)\n",
      "               If (feature 12 <= 41.0)\n",
      "                If (feature 1 <= 89.0)\n",
      "                 Predict: 2.0\n",
      "                Else (feature 1 > 89.0)\n",
      "                 If (feature 7 <= 56.0)\n",
      "                  Predict: 3.0\n",
      "                 Else (feature 7 > 56.0)\n",
      "                  Predict: 2.0\n",
      "               Else (feature 12 > 41.0)\n",
      "                Predict: 2.0\n",
      "     Else (feature 10 > 36.0)\n",
      "      If (feature 3 <= 90.0)\n",
      "       If (feature 0 <= 13.0)\n",
      "        If (feature 6 <= 50.0)\n",
      "         If (feature 1 <= 47.0)\n",
      "          Predict: 8.0\n",
      "         Else (feature 1 > 47.0)\n",
      "          If (feature 4 <= 59.0)\n",
      "           If (feature 1 <= 78.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 1 > 78.0)\n",
      "            If (feature 0 <= 0.0)\n",
      "             Predict: 5.0\n",
      "            Else (feature 0 > 0.0)\n",
      "             Predict: 9.0\n",
      "          Else (feature 4 > 59.0)\n",
      "           Predict: 9.0\n",
      "        Else (feature 6 > 50.0)\n",
      "         If (feature 5 <= 31.0)\n",
      "          If (feature 7 <= 59.0)\n",
      "           Predict: 0.0\n",
      "          Else (feature 7 > 59.0)\n",
      "           Predict: 9.0\n",
      "         Else (feature 5 > 31.0)\n",
      "          If (feature 1 <= 85.0)\n",
      "           If (feature 8 <= 37.0)\n",
      "            If (feature 0 <= 0.0)\n",
      "             Predict: 9.0\n",
      "            Else (feature 0 > 0.0)\n",
      "             Predict: 8.0\n",
      "           Else (feature 8 > 37.0)\n",
      "            If (feature 15 <= 9.0)\n",
      "             If (feature 2 <= 14.0)\n",
      "              If (feature 3 <= 85.0)\n",
      "               If (feature 5 <= 91.0)\n",
      "                Predict: 1.0\n",
      "               Else (feature 5 > 91.0)\n",
      "                If (feature 1 <= 47.0)\n",
      "                 Predict: 3.0\n",
      "                Else (feature 1 > 47.0)\n",
      "                 Predict: 1.0\n",
      "              Else (feature 3 > 85.0)\n",
      "               Predict: 7.0\n",
      "             Else (feature 2 > 14.0)\n",
      "              Predict: 1.0\n",
      "            Else (feature 15 > 9.0)\n",
      "             If (feature 0 <= 2.0)\n",
      "              Predict: 3.0\n",
      "             Else (feature 0 > 2.0)\n",
      "              Predict: 7.0\n",
      "          Else (feature 1 > 85.0)\n",
      "           If (feature 3 <= 74.0)\n",
      "            If (feature 0 <= 0.0)\n",
      "             Predict: 9.0\n",
      "            Else (feature 0 > 0.0)\n",
      "             Predict: 4.0\n",
      "           Else (feature 3 > 74.0)\n",
      "            Predict: 7.0\n",
      "       Else (feature 0 > 13.0)\n",
      "        If (feature 12 <= 31.0)\n",
      "         If (feature 5 <= 68.0)\n",
      "          If (feature 0 <= 45.0)\n",
      "           Predict: 0.0\n",
      "          Else (feature 0 > 45.0)\n",
      "           Predict: 4.0\n",
      "         Else (feature 5 > 68.0)\n",
      "          If (feature 6 <= 41.0)\n",
      "           If (feature 0 <= 38.0)\n",
      "            Predict: 9.0\n",
      "           Else (feature 0 > 38.0)\n",
      "            Predict: 5.0\n",
      "          Else (feature 6 > 41.0)\n",
      "           Predict: 1.0\n",
      "        Else (feature 12 > 31.0)\n",
      "         If (feature 7 <= 53.0)\n",
      "          If (feature 7 <= 42.0)\n",
      "           Predict: 6.0\n",
      "          Else (feature 7 > 42.0)\n",
      "           If (feature 1 <= 89.0)\n",
      "            If (feature 0 <= 38.0)\n",
      "             Predict: 8.0\n",
      "            Else (feature 0 > 38.0)\n",
      "             Predict: 0.0\n",
      "           Else (feature 1 > 89.0)\n",
      "            Predict: 4.0\n",
      "         Else (feature 7 > 53.0)\n",
      "          If (feature 1 <= 63.0)\n",
      "           If (feature 6 <= 41.0)\n",
      "            Predict: 9.0\n",
      "           Else (feature 6 > 41.0)\n",
      "            If (feature 3 <= 78.0)\n",
      "             If (feature 1 <= 47.0)\n",
      "              Predict: 8.0\n",
      "             Else (feature 1 > 47.0)\n",
      "              Predict: 1.0\n",
      "            Else (feature 3 > 78.0)\n",
      "             If (feature 0 <= 19.0)\n",
      "              Predict: 3.0\n",
      "             Else (feature 0 > 19.0)\n",
      "              Predict: 9.0\n",
      "          Else (feature 1 > 63.0)\n",
      "           If (feature 2 <= 0.0)\n",
      "            If (feature 1 <= 82.0)\n",
      "             If (feature 0 <= 19.0)\n",
      "              Predict: 9.0\n",
      "             Else (feature 0 > 19.0)\n",
      "              Predict: 1.0\n",
      "            Else (feature 1 > 82.0)\n",
      "             Predict: 9.0\n",
      "           Else (feature 2 > 0.0)\n",
      "            Predict: 9.0\n",
      "      Else (feature 3 > 90.0)\n",
      "       If (feature 9 <= 53.0)\n",
      "        If (feature 9 <= 20.0)\n",
      "         If (feature 0 <= 19.0)\n",
      "          If (feature 13 <= 8.0)\n",
      "           If (feature 2 <= 28.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 28.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 13 > 8.0)\n",
      "           Predict: 7.0\n",
      "         Else (feature 0 > 19.0)\n",
      "          If (feature 6 <= 50.0)\n",
      "           Predict: 6.0\n",
      "          Else (feature 6 > 50.0)\n",
      "           If (feature 0 <= 35.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 0 > 35.0)\n",
      "            Predict: 3.0\n",
      "        Else (feature 9 > 20.0)\n",
      "         If (feature 2 <= 98.0)\n",
      "          If (feature 14 <= 54.0)\n",
      "           If (feature 0 <= 72.0)\n",
      "            If (feature 7 <= 77.0)\n",
      "             If (feature 12 <= 8.0)\n",
      "              Predict: 1.0\n",
      "             Else (feature 12 > 8.0)\n",
      "              If (feature 4 <= 49.0)\n",
      "               If (feature 0 <= 0.0)\n",
      "                Predict: 3.0\n",
      "               Else (feature 0 > 0.0)\n",
      "                Predict: 5.0\n",
      "              Else (feature 4 > 49.0)\n",
      "               If (feature 6 <= 7.0)\n",
      "                Predict: 5.0\n",
      "               Else (feature 6 > 7.0)\n",
      "                If (feature 2 <= 85.0)\n",
      "                 If (feature 13 <= 16.0)\n",
      "                  If (feature 6 <= 99.0)\n",
      "                   If (feature 3 <= 96.0)\n",
      "                    If (feature 0 <= 38.0)\n",
      "                     Predict: 3.0\n",
      "                    Else (feature 0 > 38.0)\n",
      "                     If (feature 1 <= 74.0)\n",
      "                      Predict: 1.0\n",
      "                     Else (feature 1 > 74.0)\n",
      "                      Predict: 3.0\n",
      "                   Else (feature 3 > 96.0)\n",
      "                    Predict: 3.0\n",
      "                  Else (feature 6 > 99.0)\n",
      "                   If (feature 0 <= 0.0)\n",
      "                    Predict: 1.0\n",
      "                   Else (feature 0 > 0.0)\n",
      "                    Predict: 3.0\n",
      "                 Else (feature 13 > 16.0)\n",
      "                  If (feature 1 <= 93.0)\n",
      "                   Predict: 1.0\n",
      "                  Else (feature 1 > 93.0)\n",
      "                   Predict: 3.0\n",
      "                Else (feature 2 > 85.0)\n",
      "                 If (feature 5 <= 86.0)\n",
      "                  Predict: 3.0\n",
      "                 Else (feature 5 > 86.0)\n",
      "                  If (feature 1 <= 74.0)\n",
      "                   Predict: 1.0\n",
      "                  Else (feature 1 > 74.0)\n",
      "                   Predict: 5.0\n",
      "            Else (feature 7 > 77.0)\n",
      "             If (feature 4 <= 71.0)\n",
      "              If (feature 0 <= 45.0)\n",
      "               Predict: 3.0\n",
      "              Else (feature 0 > 45.0)\n",
      "               Predict: 9.0\n",
      "             Else (feature 4 > 71.0)\n",
      "              Predict: 5.0\n",
      "           Else (feature 0 > 72.0)\n",
      "            If (feature 6 <= 55.0)\n",
      "             If (feature 6 <= 0.0)\n",
      "              Predict: 4.0\n",
      "             Else (feature 6 > 0.0)\n",
      "              Predict: 5.0\n",
      "            Else (feature 6 > 55.0)\n",
      "             If (feature 7 <= 64.0)\n",
      "              If (feature 1 <= 94.0)\n",
      "               Predict: 3.0\n",
      "              Else (feature 1 > 94.0)\n",
      "               Predict: 1.0\n",
      "             Else (feature 7 > 64.0)\n",
      "              Predict: 9.0\n",
      "          Else (feature 14 > 54.0)\n",
      "           If (feature 15 <= 6.0)\n",
      "            If (feature 2 <= 46.0)\n",
      "             Predict: 2.0\n",
      "            Else (feature 2 > 46.0)\n",
      "             If (feature 0 <= 54.0)\n",
      "              Predict: 1.0\n",
      "             Else (feature 0 > 54.0)\n",
      "              Predict: 4.0\n",
      "           Else (feature 15 > 6.0)\n",
      "            If (feature 4 <= 56.0)\n",
      "             Predict: 2.0\n",
      "            Else (feature 4 > 56.0)\n",
      "             Predict: 7.0\n",
      "         Else (feature 2 > 98.0)\n",
      "          If (feature 5 <= 83.0)\n",
      "           If (feature 12 <= 20.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 12 > 20.0)\n",
      "            If (feature 1 <= 82.0)\n",
      "             Predict: 4.0\n",
      "            Else (feature 1 > 82.0)\n",
      "             Predict: 3.0\n",
      "          Else (feature 5 > 83.0)\n",
      "           If (feature 6 <= 80.0)\n",
      "            Predict: 5.0\n",
      "           Else (feature 6 > 80.0)\n",
      "            Predict: 9.0\n",
      "       Else (feature 9 > 53.0)\n",
      "        If (feature 0 <= 65.0)\n",
      "         If (feature 2 <= 58.0)\n",
      "          If (feature 13 <= 16.0)\n",
      "           If (feature 7 <= 92.0)\n",
      "            If (feature 14 <= 54.0)\n",
      "             If (feature 1 <= 94.0)\n",
      "              If (feature 8 <= 0.0)\n",
      "               Predict: 5.0\n",
      "              Else (feature 8 > 0.0)\n",
      "               Predict: 3.0\n",
      "             Else (feature 1 > 94.0)\n",
      "              Predict: 7.0\n",
      "            Else (feature 14 > 54.0)\n",
      "             If (feature 1 <= 88.0)\n",
      "              Predict: 2.0\n",
      "             Else (feature 1 > 88.0)\n",
      "              Predict: 7.0\n",
      "           Else (feature 7 > 92.0)\n",
      "            If (feature 0 <= 0.0)\n",
      "             Predict: 7.0\n",
      "            Else (feature 0 > 0.0)\n",
      "             Predict: 9.0\n",
      "          Else (feature 13 > 16.0)\n",
      "           If (feature 10 <= 91.0)\n",
      "            If (feature 14 <= 62.0)\n",
      "             If (feature 2 <= 40.0)\n",
      "              Predict: 7.0\n",
      "             Else (feature 2 > 40.0)\n",
      "              If (feature 11 <= 40.0)\n",
      "               Predict: 3.0\n",
      "              Else (feature 11 > 40.0)\n",
      "               Predict: 7.0\n",
      "            Else (feature 14 > 62.0)\n",
      "             If (feature 1 <= 66.0)\n",
      "              Predict: 3.0\n",
      "             Else (feature 1 > 66.0)\n",
      "              Predict: 7.0\n",
      "           Else (feature 10 > 91.0)\n",
      "            Predict: 9.0\n",
      "         Else (feature 2 > 58.0)\n",
      "          If (feature 1 <= 72.0)\n",
      "           Predict: 9.0\n",
      "          Else (feature 1 > 72.0)\n",
      "           If (feature 6 <= 63.0)\n",
      "            If (feature 9 <= 74.0)\n",
      "             Predict: 5.0\n",
      "            Else (feature 9 > 74.0)\n",
      "             If (feature 0 <= 19.0)\n",
      "              Predict: 5.0\n",
      "             Else (feature 0 > 19.0)\n",
      "              Predict: 9.0\n",
      "           Else (feature 6 > 63.0)\n",
      "            If (feature 7 <= 84.0)\n",
      "             If (feature 5 <= 99.0)\n",
      "              Predict: 3.0\n",
      "             Else (feature 5 > 99.0)\n",
      "              If (feature 0 <= 0.0)\n",
      "               Predict: 1.0\n",
      "              Else (feature 0 > 0.0)\n",
      "               Predict: 9.0\n",
      "            Else (feature 7 > 84.0)\n",
      "             Predict: 5.0\n",
      "        Else (feature 0 > 65.0)\n",
      "         If (feature 7 <= 56.0)\n",
      "          Predict: 5.0\n",
      "         Else (feature 7 > 56.0)\n",
      "          If (feature 8 <= 60.0)\n",
      "           If (feature 0 <= 99.0)\n",
      "            Predict: 9.0\n",
      "           Else (feature 0 > 99.0)\n",
      "            Predict: 5.0\n",
      "          Else (feature 8 > 60.0)\n",
      "           Predict: 9.0\n",
      "    Else (feature 15 > 27.0)\n",
      "     If (feature 3 <= 85.0)\n",
      "      If (feature 7 <= 51.0)\n",
      "       If (feature 1 <= 94.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 1 > 94.0)\n",
      "        If (feature 0 <= 45.0)\n",
      "         Predict: 7.0\n",
      "        Else (feature 0 > 45.0)\n",
      "         Predict: 6.0\n",
      "      Else (feature 7 > 51.0)\n",
      "       If (feature 11 <= 24.0)\n",
      "        Predict: 8.0\n",
      "       Else (feature 11 > 24.0)\n",
      "        If (feature 0 <= 0.0)\n",
      "         Predict: 8.0\n",
      "        Else (feature 0 > 0.0)\n",
      "         Predict: 9.0\n",
      "     Else (feature 3 > 85.0)\n",
      "      If (feature 13 <= 12.0)\n",
      "       If (feature 7 <= 36.0)\n",
      "        Predict: 2.0\n",
      "       Else (feature 7 > 36.0)\n",
      "        If (feature 1 <= 92.0)\n",
      "         Predict: 3.0\n",
      "        Else (feature 1 > 92.0)\n",
      "         If (feature 0 <= 93.0)\n",
      "          Predict: 9.0\n",
      "         Else (feature 0 > 93.0)\n",
      "          Predict: 8.0\n",
      "      Else (feature 13 > 12.0)\n",
      "       If (feature 0 <= 54.0)\n",
      "        If (feature 1 <= 63.0)\n",
      "         Predict: 8.0\n",
      "        Else (feature 1 > 63.0)\n",
      "         Predict: 7.0\n",
      "       Else (feature 0 > 54.0)\n",
      "        If (feature 0 <= 59.0)\n",
      "         Predict: 8.0\n",
      "        Else (feature 0 > 59.0)\n",
      "         Predict: 6.0\n",
      "  Else (feature 15 > 51.0)\n",
      "   If (feature 10 <= 69.0)\n",
      "    If (feature 3 <= 74.0)\n",
      "     If (feature 14 <= 71.0)\n",
      "      If (feature 12 <= 34.0)\n",
      "       If (feature 5 <= 13.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 5 > 13.0)\n",
      "        If (feature 4 <= 68.0)\n",
      "         Predict: 9.0\n",
      "        Else (feature 4 > 68.0)\n",
      "         Predict: 5.0\n",
      "      Else (feature 12 > 34.0)\n",
      "       Predict: 8.0\n",
      "     Else (feature 14 > 71.0)\n",
      "      If (feature 15 <= 75.0)\n",
      "       If (feature 3 <= 40.0)\n",
      "        Predict: 9.0\n",
      "       Else (feature 3 > 40.0)\n",
      "        Predict: 8.0\n",
      "      Else (feature 15 > 75.0)\n",
      "       If (feature 10 <= 45.0)\n",
      "        If (feature 13 <= 75.0)\n",
      "         If (feature 1 <= 89.0)\n",
      "          Predict: 8.0\n",
      "         Else (feature 1 > 89.0)\n",
      "          Predict: 5.0\n",
      "        Else (feature 13 > 75.0)\n",
      "         Predict: 5.0\n",
      "       Else (feature 10 > 45.0)\n",
      "        Predict: 8.0\n",
      "    Else (feature 3 > 74.0)\n",
      "     If (feature 0 <= 19.0)\n",
      "      If (feature 14 <= 26.0)\n",
      "       Predict: 8.0\n",
      "      Else (feature 14 > 26.0)\n",
      "       If (feature 11 <= 50.0)\n",
      "        If (feature 1 <= 47.0)\n",
      "         Predict: 8.0\n",
      "        Else (feature 1 > 47.0)\n",
      "         Predict: 7.0\n",
      "       Else (feature 11 > 50.0)\n",
      "        Predict: 5.0\n",
      "     Else (feature 0 > 19.0)\n",
      "      If (feature 6 <= 12.0)\n",
      "       If (feature 0 <= 78.0)\n",
      "        If (feature 13 <= 30.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 13 > 30.0)\n",
      "         Predict: 8.0\n",
      "       Else (feature 0 > 78.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 6 > 12.0)\n",
      "       If (feature 11 <= 65.0)\n",
      "        If (feature 0 <= 35.0)\n",
      "         If (feature 10 <= 17.0)\n",
      "          If (feature 8 <= 13.0)\n",
      "           Predict: 5.0\n",
      "          Else (feature 8 > 13.0)\n",
      "           If (feature 0 <= 25.0)\n",
      "            Predict: 8.0\n",
      "           Else (feature 0 > 25.0)\n",
      "            Predict: 7.0\n",
      "         Else (feature 10 > 17.0)\n",
      "          Predict: 8.0\n",
      "        Else (feature 0 > 35.0)\n",
      "         If (feature 7 <= 67.0)\n",
      "          If (feature 15 <= 99.0)\n",
      "           If (feature 4 <= 78.0)\n",
      "            Predict: 8.0\n",
      "           Else (feature 4 > 78.0)\n",
      "            If (feature 2 <= 85.0)\n",
      "             Predict: 8.0\n",
      "            Else (feature 2 > 85.0)\n",
      "             Predict: 7.0\n",
      "          Else (feature 15 > 99.0)\n",
      "           If (feature 14 <= 99.0)\n",
      "            Predict: 8.0\n",
      "           Else (feature 14 > 99.0)\n",
      "            If (feature 3 <= 90.0)\n",
      "             Predict: 5.0\n",
      "            Else (feature 3 > 90.0)\n",
      "             Predict: 8.0\n",
      "         Else (feature 7 > 67.0)\n",
      "          Predict: 0.0\n",
      "       Else (feature 11 > 65.0)\n",
      "        Predict: 5.0\n",
      "   Else (feature 10 > 69.0)\n",
      "    If (feature 4 <= 49.0)\n",
      "     If (feature 8 <= 56.0)\n",
      "      If (feature 9 <= 4.0)\n",
      "       If (feature 15 <= 64.0)\n",
      "        Predict: 6.0\n",
      "       Else (feature 15 > 64.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 9 > 4.0)\n",
      "       Predict: 8.0\n",
      "     Else (feature 8 > 56.0)\n",
      "      If (feature 13 <= 58.0)\n",
      "       If (feature 2 <= 23.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 2 > 23.0)\n",
      "        Predict: 6.0\n",
      "      Else (feature 13 > 58.0)\n",
      "       If (feature 2 <= 53.0)\n",
      "        If (feature 7 <= 26.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 7 > 26.0)\n",
      "         If (feature 0 <= 13.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 0 > 13.0)\n",
      "          Predict: 8.0\n",
      "       Else (feature 2 > 53.0)\n",
      "        If (feature 0 <= 65.0)\n",
      "         Predict: 8.0\n",
      "        Else (feature 0 > 65.0)\n",
      "         Predict: 0.0\n",
      "    Else (feature 4 > 49.0)\n",
      "     If (feature 8 <= 85.0)\n",
      "      If (feature 15 <= 64.0)\n",
      "       If (feature 1 <= 85.0)\n",
      "        Predict: 8.0\n",
      "       Else (feature 1 > 85.0)\n",
      "        Predict: 7.0\n",
      "      Else (feature 15 > 64.0)\n",
      "       If (feature 7 <= 56.0)\n",
      "        Predict: 8.0\n",
      "       Else (feature 7 > 56.0)\n",
      "        Predict: 0.0\n",
      "     Else (feature 8 > 85.0)\n",
      "      If (feature 0 <= 0.0)\n",
      "       Predict: 9.0\n",
      "      Else (feature 0 > 0.0)\n",
      "       Predict: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# See the trained model.\n",
    "print dtmodel._call_java('toDebugString')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test data.\n",
    "dtpredicts = dtmodel.transform(pendtvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[0.0,0.0,41.0,16....|  9.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       8.0|\n",
      "|[0.0,0.0,51.0,9.0...|  9.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       9.0|\n",
      "|[0.0,4.0,74.0,29....|  1.0|[0.0,407.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[0.0,28.0,22.0,49...|  1.0|[0.0,407.0,0.0,0....|[0.0,1.0,0.0,0.0,...|       1.0|\n",
      "|[0.0,30.0,46.0,60...|  8.0|[0.0,0.0,0.0,0.0,...|[0.0,0.0,0.0,0.0,...|       8.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtpredicts.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.0474525\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\\\n",
    "    .evaluate(dtpredicts)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {Row(label=0.0, prediction=0.0): 197,\n",
       "             Row(label=0.0, prediction=4.0): 1,\n",
       "             Row(label=0.0, prediction=6.0): 1,\n",
       "             Row(label=1.0, prediction=1.0): 179,\n",
       "             Row(label=1.0, prediction=2.0): 10,\n",
       "             Row(label=1.0, prediction=3.0): 1,\n",
       "             Row(label=1.0, prediction=6.0): 1,\n",
       "             Row(label=1.0, prediction=7.0): 1,\n",
       "             Row(label=1.0, prediction=8.0): 1,\n",
       "             Row(label=1.0, prediction=9.0): 1,\n",
       "             Row(label=2.0, prediction=1.0): 12,\n",
       "             Row(label=2.0, prediction=2.0): 197,\n",
       "             Row(label=2.0, prediction=3.0): 1,\n",
       "             Row(label=2.0, prediction=7.0): 1,\n",
       "             Row(label=3.0, prediction=0.0): 1,\n",
       "             Row(label=3.0, prediction=1.0): 1,\n",
       "             Row(label=3.0, prediction=3.0): 184,\n",
       "             Row(label=3.0, prediction=5.0): 5,\n",
       "             Row(label=3.0, prediction=9.0): 1,\n",
       "             Row(label=4.0, prediction=0.0): 1,\n",
       "             Row(label=4.0, prediction=1.0): 1,\n",
       "             Row(label=4.0, prediction=4.0): 193,\n",
       "             Row(label=4.0, prediction=5.0): 1,\n",
       "             Row(label=4.0, prediction=6.0): 3,\n",
       "             Row(label=4.0, prediction=7.0): 1,\n",
       "             Row(label=4.0, prediction=9.0): 3,\n",
       "             Row(label=5.0, prediction=1.0): 1,\n",
       "             Row(label=5.0, prediction=3.0): 2,\n",
       "             Row(label=5.0, prediction=4.0): 2,\n",
       "             Row(label=5.0, prediction=5.0): 185,\n",
       "             Row(label=5.0, prediction=6.0): 2,\n",
       "             Row(label=5.0, prediction=8.0): 2,\n",
       "             Row(label=5.0, prediction=9.0): 4,\n",
       "             Row(label=6.0, prediction=0.0): 1,\n",
       "             Row(label=6.0, prediction=1.0): 1,\n",
       "             Row(label=6.0, prediction=3.0): 1,\n",
       "             Row(label=6.0, prediction=5.0): 1,\n",
       "             Row(label=6.0, prediction=6.0): 194,\n",
       "             Row(label=6.0, prediction=7.0): 1,\n",
       "             Row(label=7.0, prediction=1.0): 1,\n",
       "             Row(label=7.0, prediction=2.0): 3,\n",
       "             Row(label=7.0, prediction=3.0): 1,\n",
       "             Row(label=7.0, prediction=7.0): 192,\n",
       "             Row(label=7.0, prediction=8.0): 1,\n",
       "             Row(label=8.0, prediction=0.0): 3,\n",
       "             Row(label=8.0, prediction=5.0): 2,\n",
       "             Row(label=8.0, prediction=7.0): 2,\n",
       "             Row(label=8.0, prediction=8.0): 195,\n",
       "             Row(label=8.0, prediction=9.0): 2,\n",
       "             Row(label=9.0, prediction=3.0): 1,\n",
       "             Row(label=9.0, prediction=4.0): 2,\n",
       "             Row(label=9.0, prediction=5.0): 5,\n",
       "             Row(label=9.0, prediction=6.0): 1,\n",
       "             Row(label=9.0, prediction=7.0): 1,\n",
       "             Row(label=9.0, prediction=8.0): 3,\n",
       "             Row(label=9.0, prediction=9.0): 191})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtpredicts.select('label','prediction').rdd.map(lambda x : (x,1)).countByKey() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.952547452547\n",
      "DenseMatrix([[ 197.,    0.,    0.,    0.,    1.,    0.,    1.,    0.,    0.,\n",
      "                 0.],\n",
      "             [   0.,  179.,   10.,    1.,    0.,    0.,    1.,    1.,    1.,\n",
      "                 1.],\n",
      "             [   0.,   12.,  197.,    1.,    0.,    0.,    0.,    1.,    0.,\n",
      "                 0.],\n",
      "             [   1.,    1.,    0.,  184.,    0.,    5.,    0.,    0.,    0.,\n",
      "                 1.],\n",
      "             [   1.,    1.,    0.,    0.,  193.,    1.,    3.,    1.,    0.,\n",
      "                 3.],\n",
      "             [   0.,    1.,    0.,    2.,    2.,  185.,    2.,    0.,    2.,\n",
      "                 4.],\n",
      "             [   1.,    1.,    0.,    1.,    0.,    1.,  194.,    1.,    0.,\n",
      "                 0.],\n",
      "             [   0.,    1.,    3.,    1.,    0.,    0.,    0.,  192.,    1.,\n",
      "                 0.],\n",
      "             [   3.,    0.,    0.,    0.,    0.,    2.,    0.,    2.,  195.,\n",
      "                 2.],\n",
      "             [   0.,    0.,    0.,    1.,    2.,    5.,    1.,    1.,    3.,\n",
      "               191.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/mllib/evaluation.py:237: UserWarning: Deprecated in 2.0.0. Use accuracy.\n",
      "  warnings.warn(\"Deprecated in 2.0.0. Use accuracy.\")\n"
     ]
    }
   ],
   "source": [
    "#Depreciated in Spark 2.0 -- Use accuracy\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "dtresrdd = dtpredicts.select(\"prediction\", \"label\").rdd #convert DataFrame to RDD.\n",
    "dtmm = MulticlassMetrics(dtresrdd) \n",
    "print dtmm.precision() \n",
    "print(dtmm.confusionMatrix())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using 5 fold validation, find the best model’s maxDepth among 5,10,15,20,25 and 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "Accuracy : 0.952535081358\n"
     ]
    }
   ],
   "source": [
    "# n-fold validation and the results.\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "#ParamGridBuilder() – combinations of parameters and their values.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(dt.maxDepth, [5,10,15,20,25,30])\\\n",
    "    .build()\n",
    "\n",
    "#setEstimatorParamMaps() takes ParamGridBuilder().\n",
    "cv = CrossValidator().setEstimator(dt).setEvaluator(evaluator).setNumFolds(5).setEstimatorParamMaps(paramGrid)\n",
    "cvmodel = cv.fit(pendttrain)\n",
    "\n",
    "print cvmodel.bestModel._java_obj.getMaxDepth()\n",
    "print \"Accuracy : \" +  str(MulticlassClassificationEvaluator().evaluate(cvmodel.bestModel.transform(pendtvalid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pipeline of VectorAssembler and DecisionTreeClassifier to create a decision tree classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
